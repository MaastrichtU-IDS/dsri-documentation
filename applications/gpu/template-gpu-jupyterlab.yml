---
kind: Template
apiVersion: template.openshift.io/v1
labels:
  template: gpu-jupyterlab
metadata:
  name: gpu-jupyterlab
  annotations:
    openshift.io/display-name: JupyterLab on GPU
    description: |-
      Start JupyterLab to run CUDA, Tensorflow, or PyTorch using GPUs with the root user.

      üì¶ We recommend you to use `conda install` to install new packages, but you can also use `sudo apt-get install` or `pip install`
    
      üìÇ Use the `/workspace/persistent` folder (workspace of the JupyterLab UI) to store your data in the persistent storage

      üê≥ You can directly use the following Docker images to work on GPU:
      - CUDA build, based on https://ngc.nvidia.com/catalog/containers/nvidia:cuda
      ghcr.io/maastrichtu-ids/jupyterlab:cuda
      - Tensorflow build, based on https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow
      ghcr.io/maastrichtu-ids/jupyterlab:tensorflow
      - PyTorch build, based on https://ngc.nvidia.com/catalog/containers/nvidia:pytorch
      ghcr.io/maastrichtu-ids/jupyterlab:pytorch
      - FSL, built with NeuroDocker and CUDA:
      ghcr.io/maastrichtu-ids/jupyterlab:fsl-gpu

      Feel free to check how the GPU images are built and to customize them for your project: https://github.com/MaastrichtU-IDS/jupyterlab

      üìãÔ∏è You can find some examples for Tensorflow and PyTorch in the following repositories:
      https://gitlab.maastrichtuniversity.nl/dsri-examples/dsri-tensorflow-workspace
      https://gitlab.maastrichtuniversity.nl/dsri-examples/dsri-pytorch-workspace

      üóëÔ∏è Use this command with your application name to delete completely your application and its persistent volumes:
      oc delete all,pvc,secret,configmaps,serviceaccount,rolebinding --selector app=$APPLICATION_NAME
    iconClass: icon-python
    tags: python,jupyter,gpu
    openshift.io/provider-display-name: Institute of Data Science, UM
    openshift.io/documentation-url: https://maastrichtu-ids.github.io/dsri-documentation/docs/deploy-on-gpu
    openshift.io/support-url: https://maastrichtu-ids.github.io/dsri-documentation/help

parameters:
- name: APPLICATION_NAME
  displayName: Application name
  description: Must be unique in the project. It will be used to generate the application
    URL.
  value: jupyterlab-gpu
  required: true
- name: IMAGE_NAME
  displayName: Docker image used
  description: 'Check the description on the right for more details about available images'
  value: 'ghcr.io/maastrichtu-ids/jupyterlab:tensorflow'
  required: true
- name: JUPYTER_TOKEN
  displayName: Notebook token
  description: The token to access the notebook
  value: mytoken
  required: true
- name: STORAGE_SIZE
  displayName: Storage size
  description: Size of the storage allocated to the notebook persistent storage in `/workspace/persistent`.
  value: 20Gi
  required: true
- name: GPU_LIMIT
  displayName: Number of GPU assigned
  description: Use 0 if no GPU has been assigned yet to your project
  value: '0'
  required: true
- name: GIT_URL
  displayName: URL of a git repository to clone in the workspace (optional)
  required: false
  description: It will be automatically cloned, then requirements.txt and packages.txt will be automatically installed if presents. Only works for images based on the official images
- name: GIT_NAME
  displayName: Git name
  required: true
  value: default
  description: Email used to automatically define git config --global user.name
- name: GIT_EMAIL
  displayName: Git email
  required: true
  value: default@maastrichtuniversity.nl
  description: Email used to automatically define git config --global user.email

- name: IMAGE_PULL_POLICY
  displayName: Image pull policy
  description: Use Always to make sure the new image is pulled when you update it
  value: 'IfNotPresent'
  required: true
# - name: WORKDIR
#   displayName: Workspace path
#   description: Path to the workspace in the container (stored in persistent storage). By default Nvidia images uses /workspace
#   value: /workspace
#   required: true

# - name: MEMORY_LIMIT
#   displayName: Memory limit
#   description: Maximum RAM memory available for the application.
#   value: "60Gi"
#   required: true
# - name: CPU_LIMIT
#   displayName: CPU limit
#   description: Number of CPUs available for the application (in millicore, 1 CPU = 1000m).
#   value: "10000m"
#   required: true
objects:

- apiVersion: v1
  kind: Secret
  metadata:
    annotations:
      template.openshift.io/expose-password: "{.data['application-password']}"
    name: "${APPLICATION_NAME}"
    labels:
      app: ${APPLICATION_NAME}
  stringData:
    application-password: "${JUPYTER_TOKEN}"

# - kind: "ImageStream"
#   apiVersion: image.openshift.io/v1
#   metadata:
#     name: ${APPLICATION_NAME}
#     labels:
#       app: ${APPLICATION_NAME}
#   spec:
#     tags:
#     - name: latest
#       from:
#         kind: DockerImage
#         name: ${IMAGE_NAME}
#       importPolicy:
#         scheduled: false
#     lookupPolicy:
#       local: true

- kind: "PersistentVolumeClaim"
  apiVersion: "v1"
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    accessModes:
      - "ReadWriteMany"
    resources:
      requests:
        storage: ${STORAGE_SIZE}

- kind: DeploymentConfig
  apiVersion: apps.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          deploymentconfig: ${APPLICATION_NAME}
      spec:
        # Automatically created by OpenShift, it is deleted when pod stopped
        tolerations:
          - effect: NoSchedule
            key: "nvidia.com/gpu"
            operator: Exists
        serviceAccountName: anyuid
        # nodeSelector:
        #   nvidia.com/gpu: 'true'
        containers:
          - name: gpu-jupyterlab
            # image: ${APPLICATION_NAME}:latest
            # imagePullPolicy: IfNotPresent
            ## In case the ImageStream does not update properly:
            image: ${IMAGE_NAME}
            imagePullPolicy: ${IMAGE_PULL_POLICY}
            # nvcr.io/nvidia/tensorflow:21.08-tf2-py3
            resources:
              requests:
                nvidia.com/gpu: '${GPU_LIMIT}'
              limits:
                nvidia.com/gpu: '${GPU_LIMIT}'
                # cpu: "${CPU_LIMIT}"
                # memory: "${MEMORY_LIMIT}"
            ports:
              - containerPort: 8888
                protocol: TCP
              - containerPort: 6006
                protocol: TCP
              # - containerPort: 6064
              #   protocol: TCP
            volumeMounts:
              - name: dshm
                mountPath: /dev/shm
              - name: data
                mountPath: /workspace/persistent
              # - name: scratch
              #   mountPath: /workspace/scratch
              #   subPath: workspace
            env:
              - name: JUPYTER_TOKEN
                valueFrom:
                  secretKeyRef:
                    key: application-password
                    name: "${APPLICATION_NAME}"
              - name: GIT_URL
                value: "${GIT_URL}"
              - name: GIT_NAME
                value: "${GIT_NAME}"
              - name: GIT_EMAIL
                value: "${GIT_EMAIL}"
              - name: WORKSPACE
                value: "/workspace"
              - name: PERSISTENT_FOLDER
                value: "/workspace/persistent"
            # command:
            #   - jupyter
            #   - lab
            #   - "--allow-root"
            #   - "--ip=0.0.0.0"
            #   - "--port=8888"
            #   - "--no-browser"
        volumes:
          - name: dshm
            emptyDir:
              medium: Memory
          - name: data
            persistentVolumeClaim:
              claimName: ${APPLICATION_NAME}
          # - name: scratch
          #   persistentVolumeClaim:
          #     claimName: gpu-scratch-storage
    selector:
      app: ${APPLICATION_NAME}
      deploymentconfig: ${APPLICATION_NAME}
    strategy:
      type: Rolling
    test: false
    triggers:
      - type: ConfigChange
      # - imageChangeParams:
      #     automatic: true
      #     containerNames:
      #       - gpu-jupyterlab
      #     from:
      #       kind: ImageStreamTag
      #       name: ${APPLICATION_NAME}:latest
      #   type: ImageChange

- kind: Service
  apiVersion: v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    ports:
    - name: 8888-tcp
      protocol: TCP
      port: 8888
      targetPort: 8888
    # - name: 6006-tcp
    #   protocol: TCP
    #   port: 6006
    #   targetPort: 6006
    selector:
      app: "${APPLICATION_NAME}"
      deploymentconfig: "${APPLICATION_NAME}"

- kind: Route
  apiVersion: route.openshift.io/v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    host: ''
    to:
      kind: Service
      name: "${APPLICATION_NAME}"
      weight: 100
    port:
      targetPort: 8888-tcp
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect
