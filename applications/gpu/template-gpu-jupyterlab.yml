---
kind: Template
apiVersion: template.openshift.io/v1
labels:
  template: gpu-jupyterlab
metadata:
  name: gpu-jupyterlab
  annotations:
    openshift.io/display-name: JupyterLab on GPU
    description: |-
      Start JupyterLab to run CUDA, Tensorflow or PyTorch using GPUs with the root user.

      üì¶ We recommend you to use `conda install` to install new packages, but you can also use `sudo apt-get install` or `pip install`
    
      üìÇ Use the `/workspace` folder (workspace of the JupyterLab UI) to store your data in the persistent storage

      üê≥ You can directly use the following Docker images to work on GPU:
      - CUDA build, based on https://ngc.nvidia.com/catalog/containers/nvidia:cuda:
      ghcr.io/maastrichtu-ids/jupyterlab:cuda
      - Tensorflow build, based on https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow:
      ghcr.io/maastrichtu-ids/jupyterlab:tensorflow
      - PyTorch build, based on https://ngc.nvidia.com/catalog/containers/nvidia:pytorch:
      ghcr.io/maastrichtu-ids/jupyterlab:pytorch
      - FSL, built with NeuroDocker and CUDA:
      ghcr.io/maastrichtu-ids/jupyterlab:fsl-gpu

      Feel free to check how the GPU images are built and to customize them for your project: https://github.com/MaastrichtU-IDS/jupyterlab

      üóëÔ∏è Use this command with your application name to delete completely your application and its persistent volumes:
      oc delete all,pvc,secret,configmaps,serviceaccount,rolebinding --selector app=$APPLICATION_NAME
    iconClass: icon-python
    tags: python,jupyter,gpu
    openshift.io/provider-display-name: Institute of Data Science, UM
    openshift.io/documentation-url: https://maastrichtu-ids.github.io/dsri-documentation/docs/deploy-on-gpu
    openshift.io/support-url: https://maastrichtu-ids.github.io/dsri-documentation/help

parameters:
- name: APPLICATION_NAME
  displayName: Application name
  description: Must be unique in the project. It will be used to generate the application
    URL.
  value: jupyterlab-gpu
  required: true
- name: IMAGE_NAME
  displayName: Docker image used
  description: 'Check the description on the right for more details about available images'
  value: 'ghcr.io/maastrichtu-ids/jupyterlab:cuda'
  required: true
- name: JUPYTER_TOKEN
  displayName: Notebook token
  description: The token to access the notebook
  value: mytoken
  required: true
- name: STORAGE_SIZE
  displayName: Storage size
  description: Size of the storage allocated to the notebook persistent storage in `/workspace`.
  value: 20Gi
  required: true
- name: GPU_LIMIT
  displayName: Number of GPU assigned
  description: 8 in total in the cluster. And your quota is 1 by default
  value: '1'
  required: true

# - name: IMAGE_PULL_POLICY
#   displayName: Image pull policy
#   description: Use Always to make sure the new image is pulled when you update it
#   value: 'IfNotPresent'
#   required: true
# - name: WORKDIR
#   displayName: Workspace path
#   description: Path to the workspace in the container (stored in persistent storage). By default Nvidia images uses /workspace
#   value: /workspace
#   required: true

# - name: MEMORY_LIMIT
#   displayName: Memory limit
#   description: Maximum RAM memory available for the application.
#   value: "60Gi"
#   required: true
# - name: CPU_LIMIT
#   displayName: CPU limit
#   description: Number of CPUs available for the application (in millicore, 1 CPU = 1000m).
#   value: "10000m"
#   required: true
objects:

- apiVersion: v1
  kind: Secret
  metadata:
    annotations:
      template.openshift.io/expose-password: "{.data['application-password']}"
    name: "${APPLICATION_NAME}"
    labels:
      app: ${APPLICATION_NAME}
  stringData:
    application-password: "${JUPYTER_TOKEN}"

- kind: "ImageStream"
  apiVersion: image.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    tags:
    - name: latest
      from:
        kind: DockerImage
        name: ${IMAGE_NAME}
      importPolicy:
        scheduled: false
    lookupPolicy:
      local: true

- kind: "PersistentVolumeClaim"
  apiVersion: "v1"
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    accessModes:
      - "ReadWriteMany"
    resources:
      requests:
        storage: ${STORAGE_SIZE}

- kind: DeploymentConfig
  apiVersion: apps.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          deploymentconfig: ${APPLICATION_NAME}
      spec:
        serviceAccountName: anyuid
        # nodeSelector:
        #   nvidia.com/gpu: 'true'
        containers:
          - name: gpu-jupyterlab
            # nvcr.io/nvidia/tensorflow:21.08-tf2-py3
            # image: ${APPLICATION_NAME}:latest
            # imagePullPolicy: IfNotPresent
            ## In case the ImageStream does not update properly:
            image: ${IMAGE_NAME}
            imagePullPolicy: Always
            resources:
              requests:
                nvidia.com/gpu: '${GPU_LIMIT}'
              limits:
                nvidia.com/gpu: '${GPU_LIMIT}'
                # cpu: "${CPU_LIMIT}"
                # memory: "${MEMORY_LIMIT}"
            ports:
              - containerPort: 8888
                protocol: TCP
              - containerPort: 6006
                protocol: TCP
              # - containerPort: 6064
              #   protocol: TCP
            volumeMounts:
              - name: data
                mountPath: /workspace/persistent
              #   subPath: workspace
              # - name: data
              #   mountPath: /root
              #   subPath: home
              - name: dshm
                mountPath: /dev/shm
            env:
              - name: JUPYTER_TOKEN
                valueFrom:
                  secretKeyRef:
                    key: application-password
                    name: "${APPLICATION_NAME}"
            command:
              - jupyter
              - lab
              - "--allow-root"
              - "--ip=0.0.0.0"
              - "--no-browser"
        volumes:
          - name: data
            persistentVolumeClaim:
              claimName: ${APPLICATION_NAME}
          - name: dshm
            emptyDir:
              medium: Memory                   
    selector:
      app: ${APPLICATION_NAME}
      deploymentconfig: ${APPLICATION_NAME}
    strategy:
      type: Rolling
    test: false
    triggers:
      - type: ConfigChange
      # - imageChangeParams:
      #     automatic: true
      #     containerNames:
      #       - gpu-jupyterlab
      #     from:
      #       kind: ImageStreamTag
      #       name: ${APPLICATION_NAME}:latest
      #   type: ImageChange

- kind: Service
  apiVersion: v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    ports:
    - name: 8888-tcp
      protocol: TCP
      port: 8888
      targetPort: 8888
    # - name: 6006-tcp
    #   protocol: TCP
    #   port: 6006
    #   targetPort: 6006
    selector:
      app: "${APPLICATION_NAME}"
      deploymentconfig: "${APPLICATION_NAME}"

- kind: Route
  apiVersion: route.openshift.io/v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    host: ''
    to:
      kind: Service
      name: "${APPLICATION_NAME}"
      weight: 100
    port:
      targetPort: 8888-tcp
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect
