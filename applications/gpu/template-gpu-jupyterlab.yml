---
kind: Template
apiVersion: template.openshift.io/v1
labels:
  template: gpu-jupyterlab
metadata:
  name: gpu-jupyterlab
  annotations:
    openshift.io/display-name: Python on GPU with JupyterLab
    description: |-
      Start JupyterLab to run Tensorflow or PyTorch using GPUs with the root user. 
    
      üìÇ Use the `/workspace/persistent` folder (workspace of the JupyterLab UI) to store your data in the existing persistent storage

      üê≥ Docker images provided by Nvidia:
      - Tensorflow:
      nvcr.io/nvidia/tensorflow:21.05-tf2-py3
      Check the latest version available here: https://ngc.nvidia.com/catalog/containers/nvidia:tensorflow
      - PyTorch:
      nvcr.io/nvidia/pytorch:21.05-py3
      Check the latest version available here: https://ngc.nvidia.com/catalog/containers/nvidia:pytorch
    iconClass: icon-python
    tags: python,jupyter,gpu
    openshift.io/provider-display-name: Institute of Data Science, UM
    openshift.io/documentation-url: https://maastrichtu-ids.github.io/dsri-documentation/docs/deploy-on-gpu
    openshift.io/support-url: https://maastrichtu-ids.github.io/dsri-documentation/help

parameters:
- name: APPLICATION_NAME
  displayName: Application name
  description: Must be unique in the project. It will be used to generate the application
    URL.
  value: gpu-jupyterlab
  required: true
- name: IMAGE_NAME
  displayName: Docker image used
  description: 'Also available: nvcr.io/nvidia/pytorch:21.05-py3'
  value: 'nvcr.io/nvidia/tensorflow:21.05-tf2-py3'
  required: true
- name: JUPYTER_TOKEN
  displayName: Notebook token
  description: The token to access the notebook
  value: mytoken
  required: true
- name: STORAGE_SIZE
  displayName: Storage size
  description: Size of the storage allocated to the notebook persistent storage in `/workspace/persistent`.
  value: 20Gi
  required: true
- name: GPU_LIMIT
  displayName: Number of GPU assigned
  description: 8 in total in the cluster. And your quota is 1 by default
  value: '1'
  required: true

# - name: MEMORY_LIMIT
#   displayName: Memory limit
#   description: Maximum RAM memory available for the application.
#   value: "60Gi"
#   required: true
# - name: CPU_LIMIT
#   displayName: CPU limit
#   description: Number of CPUs available for the application (in millicore, 1 CPU = 1000m).
#   value: "10000m"
#   required: true
objects:

# - apiVersion: v1
#   kind: Secret
#   metadata:
#     annotations:
#       template.openshift.io/expose-password: "{.data['application-password']}"
#     name: "${APPLICATION_NAME}"
#   stringData:
#     application-password: "${JUPYTER_TOKEN}"

- kind: "ImageStream"
  apiVersion: image.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    tags:
    - name: latest
      from:
        kind: DockerImage
        name: ${IMAGE_NAME}
      importPolicy:
        scheduled: false
    lookupPolicy:
      local: true

- kind: "PersistentVolumeClaim"
  apiVersion: "v1"
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    accessModes:
      - "ReadWriteMany"
    resources:
      requests:
        storage: ${STORAGE_SIZE}

- kind: DeploymentConfig
  apiVersion: apps.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
  spec:
    replicas: 1
    template:
      metadata:
        labels:
          app: ${APPLICATION_NAME}
          deploymentconfig: ${APPLICATION_NAME}
      spec:
        serviceAccountName: anyuid
        # nodeSelector:
        #   nvidia.com/gpu: 'true'
        containers:
          - command:
              - jupyter
              - lab
            image: ${APPLICATION_NAME}:latest
            # image: ${IMAGE_NAME}
            imagePullPolicy: IfNotPresent
            name: gpu-jupyterlab
            resources:
              requests:
                nvidia.com/gpu: '${GPU_LIMIT}'
              limits:
                nvidia.com/gpu: '${GPU_LIMIT}'
                # cpu: "${CPU_LIMIT}"
                # memory: "${MEMORY_LIMIT}"
            ports:
              - containerPort: 8888
                protocol: TCP
              - containerPort: 6006
                protocol: TCP
              # - containerPort: 6064
              #   protocol: TCP
            volumeMounts:
              - name: workdir
                mountPath: /workspace/persistent
                # subPath: ${STORAGE_FOLDER}
              - name: dshm
                mountPath: /dev/shm                
            env:
              - name: JUPYTER_TOKEN
                value: ${JUPYTER_TOKEN}
              # - name: JUPYTER_TOKEN
              #   valueFrom:
              #     secretKeyRef:
              #       key: application-password
              #       name: "${APPLICATION_NAME}"
        volumes:
          - name: workdir
            persistentVolumeClaim:
              claimName: ${APPLICATION_NAME}
          - name: dshm
            emptyDir:
              medium: Memory                   
    selector:
      app: ${APPLICATION_NAME}
      deploymentconfig: ${APPLICATION_NAME}
    strategy:
      type: Rolling
    test: false
    triggers:
      - type: ConfigChange
      # - imageChangeParams:
      #     automatic: true
      #     containerNames:
      #       - gpu-jupyterlab
      #     from:
      #       kind: ImageStreamTag
      #       name: ${APPLICATION_NAME}:latest
      #   type: ImageChange

- kind: Service
  apiVersion: v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    ports:
    - name: 8888-tcp
      protocol: TCP
      port: 8888
      targetPort: 8888
    # - name: 6006-tcp
    #   protocol: TCP
    #   port: 6006
    #   targetPort: 6006
    selector:
      app: "${APPLICATION_NAME}"
      deploymentconfig: "${APPLICATION_NAME}"

- kind: Route
  apiVersion: route.openshift.io/v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    host: ''
    to:
      kind: Service
      name: "${APPLICATION_NAME}"
      weight: 100
    port:
      targetPort: 8888-tcp
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect

# Route for Tensorboard?

# - kind: Route
#   apiVersion: route.openshift.io/v1
#   metadata:
#     name: "${APPLICATION_NAME}-tensorboard"
#     labels:
#       app: "${APPLICATION_NAME}"
#   spec:
#     host: ''
#     to:
#       kind: Service
#       name: "${APPLICATION_NAME}"
#       weight: 100
#     port:
#       targetPort: 6006-tcp
#     tls:
#       termination: edge
#       insecureEdgeTerminationPolicy: Redirect