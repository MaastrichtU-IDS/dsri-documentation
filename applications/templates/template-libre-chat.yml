---
kind: Template
apiVersion: template.openshift.io/v1
labels:
  template: libre-chat
metadata:
  name: libre-chat
  annotations:
    openshift.io/display-name: Libre Chat
    description: |-
      Deploy a fully self-hosted chatbot web service based on open source Large Language Models (LLMs), such as Llama 2

      Checkout the documentation at https://vemonet.github.io/libre-chat for more details on how to configure your chatbot
      You can also find examples config available at https://github.com/vemonet/libre-chat/blob/main/config

      üìÇ You can find the persistent storage in the DSRI web UI, go to Search > Resources > Persistent Volume Claim.

      üóëÔ∏è Use this command with your application name to delete completely your application and its persistent volumes:
      oc delete all,pvc,secret,configmaps,serviceaccount,rolebinding --selector app=$APPLICATION_NAME
    iconClass: icon-rh-integration
    tags: chatbot,llm,llama2,chatgpt
    openshift.io/provider-display-name: Institute of Data Science, UM
    openshift.io/documentation-url: https://vemonet.github.io/libre-chat
    openshift.io/support-url: https://maastrichtu-ids.github.io/dsri-documentation/help

parameters:
- name: APPLICATION_NAME
  displayName: Name for the application
  description: Must be without spaces (use -), and unique in the project.
  value: libre-chat
  required: true
- name: APPLICATION_IMAGE
  displayName: Docker image for Libre Chat
  value: ghcr.io/vemonet/libre-chat:main
  required: true
  description: Check the description on the right for more details about available images
- name: LIBRECHAT_CONF_URL
  displayName: Direct URL to the YAML configuration file for the chatbot
  required: true
  value: https://raw.github.com/vemonet/libre-chat/main/config/chat-conversation.yml
  description: Checkout the documentation at https://vemonet.github.io/libre-chat for more details on how to configure your chatbot
- name: LIBRECHAT_WORKERS
  displayName: Number of workers for the API
  required: true
  value: "4"
- name: STORAGE_SIZE
  displayName: Storage size
  description: Size of the storage allocated to the notebook persistent storage.
  value: 20Gi
  required: true
- name: MEMORY_MIN
  displayName: Memory minimum
  description: Minimum RAM memory available for the application.
  value: "16Gi"
  required: true
- name: CPU_MIN
  displayName: CPU minimum
  description: Minimum number of CPUs available for the application.
  value: "8"
  required: true
- name: MEMORY_LIMIT
  displayName: Memory limit
  description: Maximum RAM memory available for the application.
  value: "32Gi"
  required: true
- name: CPU_LIMIT
  displayName: CPU limit
  description: Max number of CPUs available for the application.
  value: "16"
  required: true

objects:
- kind: "ImageStream"
  apiVersion: image.openshift.io/v1
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: ${APPLICATION_NAME}
      template: libre-chat
  spec:
    tags:
    - name: latest
      from:
        kind: DockerImage
        name: ${APPLICATION_IMAGE}
      importPolicy:
        scheduled: false
    lookupPolicy:
      local: true

- kind: "PersistentVolumeClaim"
  apiVersion: "v1"
  metadata:
    name: ${APPLICATION_NAME}
    labels:
      app: "${APPLICATION_NAME}"
      template: libre-chat
  spec:
    accessModes:
      - "ReadWriteMany"
    resources:
      requests:
        storage: ${STORAGE_SIZE}

- kind: Deployment
  apiVersion: apps/v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
      template: libre-chat
  spec:
    replicas: 1
    strategy:
      type: Recreate
    selector:
      matchLabels:
        app: "${APPLICATION_NAME}"
        deployment: "${APPLICATION_NAME}"
    template:
      metadata:
        annotations:
          io.kubernetes.cri-o.TrySkipVolumeSELinuxLabel: 'true'
        labels:
          app: "${APPLICATION_NAME}"
          deployment: "${APPLICATION_NAME}"
      spec:
        runtimeClassName: selinux
        serviceAccountName: "anyuid"
        containers:
        - name: libre-chat-api
          image: "${APPLICATION_IMAGE}"
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 8000
            protocol: TCP
          env:
          - name: LIBRECHAT_CONF_URL
            value: "${LIBRECHAT_CONF_URL}"
          - name: LIBRECHAT_WORKERS
            value: "${LIBRECHAT_WORKERS}"
          volumeMounts:
          - name: data
            mountPath: /data
          - name: dshm
            mountPath: /dev/shm
          readinessProbe:
            tcpSocket:
              port: 8000
          livenessProbe:
            initialDelaySeconds: 15
            tcpSocket:
              port: 8000
            failureThreshold: 40
            periodSeconds: 10
            timeoutSeconds: 2
          resources:
            requests:
              cpu: "${CPU_MIN}"
              memory: "${MEMORY_MIN}"
            limits:
              cpu: "${CPU_LIMIT}"
              memory: "${MEMORY_LIMIT}"
        automountServiceAccountToken: false
        volumes:
        - name: data
          persistentVolumeClaim:
            claimName: "${APPLICATION_NAME}"
        - name: dshm
          emptyDir:
            medium: Memory

- kind: Service
  apiVersion: v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
      template: libre-chat
  spec:
    ports:
    - name: 8000-tcp
      protocol: TCP
      port: 8000
      targetPort: 8000
    selector:
      app: "${APPLICATION_NAME}"
      deployment: "${APPLICATION_NAME}"
    type: ClusterIP

- kind: Route
  apiVersion: v1
  metadata:
    name: "${APPLICATION_NAME}"
    labels:
      app: "${APPLICATION_NAME}"
  spec:
    host: ''
    to:
      kind: Service
      name: "${APPLICATION_NAME}"
      weight: 100
    port:
      targetPort: 8000-tcp
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect