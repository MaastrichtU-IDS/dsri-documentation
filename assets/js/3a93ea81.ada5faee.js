"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[6099],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>m});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var i=n.createContext({}),s=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},u=function(e){var t=s(e.components);return n.createElement(i.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,u=p(e,["components","mdxType","originalType","parentName"]),d=s(a),m=r,k=d["".concat(i,".").concat(m)]||d[m]||c[m]||o;return a?n.createElement(k,l(l({ref:t},u),{},{components:a})):n.createElement(k,l({ref:t},u))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,l=new Array(o);l[0]=d;var p={};for(var i in t)hasOwnProperty.call(t,i)&&(p[i]=t[i]);p.originalType=e,p.mdxType="string"==typeof e?e:r,l[1]=p;for(var s=2;s<o;s++)l[s]=a[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},7489:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>i,default:()=>m,frontMatter:()=>p,metadata:()=>s,toc:()=>c});var n=a(7462),r=a(3366),o=(a(7294),a(3905)),l=["components"],p={id:"jupyterhub-spark",title:"JupyterHub with Spark"},i=void 0,s={unversionedId:"jupyterhub-spark",id:"jupyterhub-spark",title:"JupyterHub with Spark",description:"JupyterHub is ideal to enable multiple users easily start predefined workspaces in the same project. The complimentary Apache Spark cluster can be used from the workspaces to perform distributed processing.",source:"@site/docs/jupyterhub-spark.md",sourceDirName:".",slug:"/jupyterhub-spark",permalink:"/docs/jupyterhub-spark",editUrl:"https://github.com/MaastrichtU-IDS/dsri-documentation/edit/master/website/docs/jupyterhub-spark.md",tags:[],version:"current",lastUpdatedBy:"Vincent Emonet",lastUpdatedAt:1663165606,formattedLastUpdatedAt:"9/14/2022",frontMatter:{id:"jupyterhub-spark",title:"JupyterHub with Spark"}},u={},c=[{value:"\ud83e\uddca Install kfctl",id:"-install-kfctl",level:2},{value:"\ud83e\ude90 Deploy JupyterHub and Spark",id:"-deploy-jupyterhub-and-spark",level:2},{value:"\u2728 Use the Spark cluster",id:"-use-the-spark-cluster",level:2},{value:"Match the version",id:"match-the-version",level:3},{value:"Spark UI",id:"spark-ui",level:3},{value:"New Spark cluster",id:"new-spark-cluster",level:3},{value:"\ud83d\uddd1\ufe0f Delete the deployment",id:"\ufe0f-delete-the-deployment",level:2}],d={toc:c};function m(e){var t=e.components,a=(0,r.Z)(e,l);return(0,o.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"JupyterHub is ideal to enable multiple users easily start predefined workspaces in the same project. The complimentary Apache Spark cluster can be used from the workspaces to perform distributed processing."),(0,o.kt)("h2",{id:"-install-kfctl"},"\ud83e\uddca Install kfctl"),(0,o.kt)("p",null,"You will need to have the usual ",(0,o.kt)("inlineCode",{parentName:"p"},"oc")," tool installed, and to install ",(0,o.kt)("inlineCode",{parentName:"p"},"kfctl")," on your machine, a tool to deploy Kubeflow applications, download the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/kubeflow/kfctl/releases"},"latest version for your OS \ud83d\udce5\ufe0f")," "),(0,o.kt)("p",null,"You can then install it by downloading the binary and putting it in your path, for example on Linux:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://github.com/kubeflow/kfctl/releases/download/v1.2.0/kfctl_v1.2.0-0-gbc038f9_linux.tar.gz\ntar -xzf kfctl_v1.2.0-0-gbc038f9_linux.tar.gz\nsudo mv kfctl /usr/local/bin/\n")),(0,o.kt)("p",null,"Clone the repository with the DSRI custom images and deployments for the OpenDataHub platform, and go to the ",(0,o.kt)("inlineCode",{parentName:"p"},"kfdef")," folder:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/MaastrichtU-IDS/odh-manifests\ncd odh-manifests/kfdef\n")),(0,o.kt)("h2",{id:"-deploy-jupyterhub-and-spark"},"\ud83e\ude90 Deploy JupyterHub and Spark"),(0,o.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"Go the the kfdef folder")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"All scripts need to be run from the ",(0,o.kt)("inlineCode",{parentName:"p"},"kfdef")," folder \ud83d\udcc2"))),(0,o.kt)("p",null,"You can deploy JupyterHub with 2 different authentications system, use the file corresponding to your choice:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"For the default DSRI authentication use ",(0,o.kt)("inlineCode",{parentName:"p"},"kfctl_openshift_dsri.yaml"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"For GitHub authentication use ",(0,o.kt)("inlineCode",{parentName:"p"},"kfctl_openshift_github.yaml")),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"You need to create a new GitHub OAuth app: ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/settings/developers"},"https://github.com/settings/developers"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"And provide the GitHub client ID and secret through environment variable before running the start script:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"export GITHUB_CLIENT_ID=YOUR_CLIENT_ID\nexport GITHUB_CLIENT_SECRET=YOUR_CLIENT_SECRET\n")))))),(0,o.kt)("p",null,"First you will need to change the ",(0,o.kt)("inlineCode",{parentName:"p"},"namespace:")," in the file you want to deploy, to provide the project where you want to start JupyterHub (currently ",(0,o.kt)("inlineCode",{parentName:"p"},"opendatahub-ids"),"), then you can deploy JupyterHub and Spark with ",(0,o.kt)("inlineCode",{parentName:"p"},"kfctl"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"./start_odh.sh kfctl_openshift_dsri.yaml\n")),(0,o.kt)("p",null,"\ud83d\uddc4\ufe0f Persistent volumes are automatically created for each instance started in JupyterHub to insure persistence of the data even JupyterHub is stopped. You can find the persistent volumes in the DSRI web UI, go to the ",(0,o.kt)("strong",{parentName:"p"},"Administrator")," view > ",(0,o.kt)("strong",{parentName:"p"},"Storage")," > ",(0,o.kt)("strong",{parentName:"p"},"Persistent Volume Claims"),"."),(0,o.kt)("p",null,"\u26a1\ufe0f A Spark cluster with 3 workers is automatically created with the service name ",(0,o.kt)("inlineCode",{parentName:"p"},"spark-cluster"),", you can use the URL of the master node to access it from your workspace: ",(0,o.kt)("inlineCode",{parentName:"p"},"spark://spark-cluster:7077")),(0,o.kt)("h2",{id:"-use-the-spark-cluster"},"\u2728 Use the Spark cluster"),(0,o.kt)("div",{className:"admonition admonition-caution alert alert--warning"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"Matching Spark versions")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"Make sure all the Spark versions are matching, the current default version is ",(0,o.kt)("inlineCode",{parentName:"p"},"3.0.1")))),(0,o.kt)("p",null,"You can test the Spark cluster connection with PySpark:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from pyspark.sql import SparkSession, SQLContext\nimport os\nimport socket\n# Create a Spark session\nspark_cluster_url = \"spark://spark-cluster:7077\"\nspark = SparkSession.builder.master(spark_cluster_url).getOrCreate()\nsc = spark.sparkContext\n\n# Test your Spark connection\nspark.range(5, numPartitions=5).rdd.map(lambda x: socket.gethostname()).distinct().collect()\n# Or try:\n#x = ['spark', 'rdd', 'example', 'sample', 'example']\nx = [1, 2, 3, 4, 5]\ny = sc.parallelize(x)\ny.collect()\n# Or try:\ndata = [1, 2, 3, 4, 5]\ndistData = sc.parallelize(data)\ndistData.reduce(lambda a, b: a + b)\n")),(0,o.kt)("h3",{id:"match-the-version"},"Match the version"),(0,o.kt)("p",null,"Make sure all the Spark versions are matching, the current default version is ",(0,o.kt)("inlineCode",{parentName:"p"},"3.0.1"),":"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Go to the Spark UI to verify the version of the Spark cluster"),(0,o.kt)("li",{parentName:"ul"},"Run ",(0,o.kt)("inlineCode",{parentName:"li"},"spark-shell --version")," to verify the version of the Spark binary installed in the workspace"),(0,o.kt)("li",{parentName:"ul"},"Run ",(0,o.kt)("inlineCode",{parentName:"li"},"pip list | grep pyspark")," to verify the version of the PySpark library")),(0,o.kt)("p",null,"Check the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/MaastrichtU-IDS/jupyterlab/blob/main/Dockerfile#L14"},"JupyterLab workspace ",(0,o.kt)("inlineCode",{parentName:"a"},"Dockerfile"))," to change the version of Spark installed in the workspace, and see how you can download and install a new version of the Spark binary."),(0,o.kt)("p",null,"If you need to change the Python, Java or PySpark version in the workspace you can create a ",(0,o.kt)("inlineCode",{parentName:"p"},"environment.yml")," file, for example for ",(0,o.kt)("inlineCode",{parentName:"p"},"2.4.5"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"name: spark\nchannels:\n  - defaults\n  - conda-forge\n  - anaconda\ndependencies:\n  - python=3.7\n  - openjdk=8\n  - ipykernel \n  - nb_conda_kernels\n  - pip\n  - pip:\n    - pyspark==2.4.5\n")),(0,o.kt)("p",null,"Create the environment with ",(0,o.kt)("inlineCode",{parentName:"p"},"conda"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"mamba env create -f environment.yml\n")),(0,o.kt)("h3",{id:"spark-ui"},"Spark UI"),(0,o.kt)("p",null,"You can also create a route to access the Spark UI and monitor the activity on the Spark cluster:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"oc expose svc/spark-cluster-ui\n")),(0,o.kt)("p",null,"Get the Spark UI URL:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"oc get route --selector radanalytics.io/service=ui --no-headers -o=custom-columns=HOST:.spec.host\n")),(0,o.kt)("h3",{id:"new-spark-cluster"},"New Spark cluster"),(0,o.kt)("p",null,"You can create a new Spark cluster, for example here using Spark ",(0,o.kt)("inlineCode",{parentName:"p"},"3.0.1")," with the installed Spark Operator:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat <<EOF | oc apply -f -\napiVersion: radanalytics.io/v1\nkind: SparkCluster\nmetadata:\n  name: spark-cluster\nspec:\n  customImage: quay.io/radanalyticsio/openshift-spark:3.0.1-2\n  worker:\n    instances: '10'\n    memory: \"4Gi\"\n    cpu: 4\n  master:\n    instances: '1'\n    memory: \"4Gi\"\n    cpu: 4\n  env:\n  - name: SPARK_WORKER_CORES\n    value: 4\nEOF\n")),(0,o.kt)("p",null,"You can browse the list of available ",(0,o.kt)("a",{parentName:"p",href:"https://quay.io/repository/radanalyticsio/openshift-spark?tag=latest&tab=tags"},"image versions here")),(0,o.kt)("p",null,"See the Radanalytics ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/radanalyticsio/spark-operator/blob/master/examples/cluster-with-config.yaml"},"Spark operator example configuration")," for more details on the Spark cluster configuration. "),(0,o.kt)("h2",{id:"\ufe0f-delete-the-deployment"},"\ud83d\uddd1\ufe0f Delete the deployment"),(0,o.kt)("p",null,"Delete the running JupyterHub application and Spark cluster, including persistent volumes:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"./delete_odh.sh kfctl_openshift_dsri.yaml\n")))}m.isMDXComponent=!0}}]);