"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[1793],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>f});var o=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,o,n=function(e,t){if(null==e)return{};var r,o,n={},i=Object.keys(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)r=i[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var s=o.createContext({}),c=function(e){var t=o.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},p=function(e){var t=c(e.components);return o.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=c(r),f=n,m=d["".concat(s,".").concat(f)]||d[f]||u[f]||i;return r?o.createElement(m,a(a({ref:t},p),{},{components:r})):o.createElement(m,a({ref:t},p))}));function f(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,a=new Array(i);a[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,a[1]=l;for(var c=2;c<i;c++)a[c]=r[c];return o.createElement.apply(null,a)}return o.createElement.apply(null,r)}d.displayName="MDXCreateElement"},2010:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>f,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var o=r(3117),n=r(102),i=(r(7294),r(3905)),a=["components"],l={id:"profile-pytorch-code",title:"PyTorch Profiling"},s=void 0,c={unversionedId:"profile-pytorch-code",id:"profile-pytorch-code",title:"PyTorch Profiling",description:"What is profiling?",source:"@site/docs/profile-pytorch-code.md",sourceDirName:".",slug:"/profile-pytorch-code",permalink:"/docs/profile-pytorch-code",draft:!1,editUrl:"https://github.com/MaastrichtU-IDS/dsri-documentation/edit/master/website/docs/profile-pytorch-code.md",tags:[],version:"current",lastUpdatedBy:"lwinckers",lastUpdatedAt:1733311229,formattedLastUpdatedAt:"Dec 4, 2024",frontMatter:{id:"profile-pytorch-code",title:"PyTorch Profiling"},sidebar:"docs",previous:{title:"Increase your processes speed",permalink:"/docs/increase-process-speed"},next:{title:"Tensorflow Optimization",permalink:"/docs/speeding-tensorflow-dl"}},p={},u=[{value:"What is profiling?",id:"what-is-profiling",level:2},{value:"Why should I care about profiling?",id:"why-should-i-care-about-profiling",level:2},{value:"When should I care about profiling?",id:"when-should-i-care-about-profiling",level:2},{value:"How DSRI team can help you?",id:"how-dsri-team-can-help-you",level:2},{value:"External Resources and references",id:"external-resources-and-references",level:2}],d={toc:u};function f(e){var t=e.components,r=(0,n.Z)(e,a);return(0,i.kt)("wrapper",(0,o.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"what-is-profiling"},"What is profiling?"),(0,i.kt)("p",null,"According to wikipedia:"),(0,i.kt)("p",null,'"Profiling is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls. Most commonly, profiling information serves to aid program optimization, and more specifically, performance engineering."'),(0,i.kt)("h2",{id:"why-should-i-care-about-profiling"},"Why should I care about profiling?"),(0,i.kt)("p",null,"You may know that training large models like GPT-3 takes several million dollars source and a few hundred MWh source. If the engineers that trained these models did not spend time on optimization, it might have been several million dollars and hunderds of MWh more."),(0,i.kt)("p",null,"Sure, the model you'd like to train is probably not quite as big. But maybe you want to train it 10000 times, because you want to do hyperparameter optimization. And even if you only train it once, it may take quite a bit of compute resources, i.e. money and energy."),(0,i.kt)("h2",{id:"when-should-i-care-about-profiling"},"When should I care about profiling?"),(0,i.kt)("p",null,"Well, you should always care if your code runs efficiently, but there's different levels of caring."),(0,i.kt)("p",null,"From personal experience: if I know I'm going to run a code only once, for a few days, on a single GPU, I'll probably not create a full profile. What I would do is inspect my GPU and CPU utilization during my runs, just to see if it is somewhat efficient, and if I didn't make any obvious mistakes (e.g. accidentally not using the GPU, even if I have one available)."),(0,i.kt)("p",null,"If I know that I'll run my code on multiple GPUs, for multiple days, (potentially) on multiple nodes, and/or I need to run it multiple times, I know that my resource footprint is going to be large, and it's worth spending some time and effort to optimize the code. That's when I'll create a profile. The good part is: the more often you do it, the quicker and more adapt you become at it."),(0,i.kt)("h2",{id:"how-dsri-team-can-help-you"},"How DSRI team can help you?"),(0,i.kt)("p",null,"We can assist you  with analyzing the bottleneck/s in your deep learning pipeline and recommend the improvments to speed up your pipeline."),(0,i.kt)("h2",{id:"external-resources-and-references"},"External Resources and references"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"This documentation is taken from the Surf's PyTorch profiling wiki (",(0,i.kt)("a",{parentName:"li",href:"https://servicedesk.surf.nl/wiki/display/WIKI/PyTorch+Profiling"},"https://servicedesk.surf.nl/wiki/display/WIKI/PyTorch+Profiling"),")"),(0,i.kt)("li",{parentName:"ul"},"Tutorial on PyTorch profiling can be found here: (",(0,i.kt)("a",{parentName:"li",href:"https://github.com/sara-nl/PraceHPML2022/blob/master/notebooks/PyTorch_profiling/PyTorch_profiling.ipynb"},"https://github.com/sara-nl/PraceHPML2022/blob/master/notebooks/PyTorch_profiling/PyTorch_profiling.ipynb"),")")))}f.isMDXComponent=!0}}]);